/**
 * æ™ºèƒ½ç« èŠ‚ç¼–è¾‘çš„LLMä»£ç†æ¶æ„
 *
 * æ­¤ä»£ç†ä½¿ç”¨å¤šæ­¥æ¨ç†è¿‡ç¨‹æ¥åˆ†æå’Œæ”¹è¿›ç« èŠ‚
 */

import { ParsedChapterPlan, AgentLogEntry } from '../types';
import { getFormattedPrompt, PromptNames } from './promptLoader';
import { generateText } from '../services/llm';

// LLMç”Ÿæˆå‡½æ•°çš„ç±»å‹
type LLMGenerateFunction = (
  prompt: string,
  systemInstruction?: string,
  responseSchema?: object,
  temperature?: number,
  topP?: number,
  topK?: number
) => Promise<string>;

export interface EditingContext {
  chapterContent: string;
  chapterPlan: ParsedChapterPlan;
  chapterPlanText: string;
  critiqueNotes: string;
  chapterNumber: number;
  onLog?: (entry: AgentLogEntry) => void; // UIæ—¥å¿—çš„å›è°ƒå‡½æ•°
}

export interface AgentDecision {
  strategy: 'targeted-edit' | 'regenerate' | 'polish' | 'skip';
  reasoning: string;
  priority: 'high' | 'medium' | 'low';
  estimatedChanges: string;
  confidence: number; // 0-100ï¼Œä»£ç†å¯¹æ­¤å†³ç­–çš„ç½®ä¿¡åº¦
}

export interface EditingResult {
  refinedContent: string;
  decision: AgentDecision;
  changesApplied: string[];
  qualityScore: number;
  logs: AgentLogEntry[]; // All logs from this editing session
}

/**
 * åˆ›å»ºå¹¶å‘å‡ºæ—¥å¿—æ¡ç›®çš„è¾…åŠ©å‡½æ•°
 */
function log(context: EditingContext, type: AgentLogEntry['type'], message: string, details?: any) {
  const entry: AgentLogEntry = {
    timestamp: Date.now(),
    chapterNumber: context.chapterNumber,
    type,
    message,
    details
  };
  
  // Console log
  const emoji = {
    decision: 'ğŸ¤–',
    execution: 'âš™ï¸',
    evaluation: 'ğŸ“Š',
    iteration: 'ğŸ”„',
    warning: 'âš ï¸',
    success: 'âœ…'
  }[type];
  
  console.log(`${emoji} ${message}`, details || '');
  
  // UI callback
  if (context.onLog) {
    context.onLog(entry);
  }
}

/**
 * æ­¥éª¤1ï¼šä»£ç†åˆ†ææƒ…å†µå¹¶å†³å®šç­–ç•¥
 */
export async function analyzeAndDecide(context: EditingContext): Promise<AgentDecision> {
  const { systemPrompt, userPrompt: analysisPrompt } = getFormattedPrompt(PromptNames.EDITING_AGENT_ANALYSIS, {
    chapter_number: context.chapterNumber,
    critique_notes: context.critiqueNotes || 'æœªå‘ç°é—®é¢˜',
    chapter_plan_text: context.chapterPlanText,
    chapter_length: context.chapterContent.length
  });
  
  try {
    const responseSchema = {
      type: 'object' as const,
      additionalProperties: false,
      properties: {
        strategy: { type: 'string' as const, enum: ['targeted-edit', 'regenerate', 'polish', 'skip'] },
        reasoning: { type: 'string' as const },
        priority: { type: 'string' as const, enum: ['high', 'medium', 'low'] },
        estimatedChanges: { type: 'string' as const },
        confidence: { type: 'number' as const, description: 'ç½®ä¿¡åº¦0-100ã€‚é«˜ç½®ä¿¡åº¦(80+)è¡¨ç¤ºå†³ç­–æ˜ç¡®ã€‚ä½ç½®ä¿¡åº¦(<60)è¡¨ç¤ºä¸ç¡®å®šã€‚' }
      },
      required: ['strategy', 'reasoning', 'priority', 'estimatedChanges', 'confidence']
    };
    
    const response = await generateText('editing', analysisPrompt, systemPrompt, responseSchema, 0.3, 0.7, 20);
    const decision = JSON.parse(response);
    
    // Log decision
    log(context, 'decision', `Strategy: ${decision.strategy} - ${decision.reasoning}`, {
      strategy: decision.strategy,
      confidence: decision.confidence,
      priority: decision.priority,
      estimatedChanges: decision.estimatedChanges
    });
    
    if (decision.confidence < 60) {
      log(context, 'warning', `LOW CONFIDENCE (${decision.confidence}%) - Agent is uncertain`, {
        confidence: decision.confidence
      });
    }
    
    return decision;
  } catch (e) {
    console.warn('Agent decision failed, falling back to heuristics:', e);
    return fallbackDecision(context);
  }
}

/**
 * Fallback decision logic if agent fails
 */
function fallbackDecision(context: EditingContext): AgentDecision {
  const critique = context.critiqueNotes.toLowerCase();

  if (!context.critiqueNotes || context.critiqueNotes.includes('ç« èŠ‚å¾ˆæ£’') || context.critiqueNotes.includes('ç« èŠ‚å¼ºåŠ²')) {
    return {
      strategy: 'skip',
      reasoning: 'æœªå‘ç°é—®é¢˜æˆ–ç« èŠ‚æ ‡è®°ä¸ºå¼ºåŠ²',
      priority: 'low',
      estimatedChanges: '0%',
      confidence: 90
    };
  }

  if (critique.includes('é“å¾·ç®€å•') || critique.includes('å¹³æ·¡') || critique.includes('åŸå‹åŒ–') || critique.includes('åˆ»æ¿å°è±¡')) {
    return {
      strategy: 'regenerate',
      reasoning: 'æ£€æµ‹åˆ°ä¸¥é‡çš„ç»“æ„æ€§é—®é¢˜',
      priority: 'high',
      estimatedChanges: '40-60%',
      confidence: 75
    };
  }

  if (critique.includes('æ¯”å–»') || critique.includes('å½¢å®¹è¯') || critique.includes('å‰¯è¯') || critique.includes('è¿‡åº¦å†™ä½œ')) {
    return {
      strategy: 'targeted-edit',
      reasoning: 'æ£€æµ‹åˆ°è¯­è¨€å±‚é¢çš„é—®é¢˜',
      priority: 'medium',
      estimatedChanges: '10-20%',
      confidence: 70
    };
  }

  return {
    strategy: 'polish',
      reasoning: 'éœ€è¦å°å¹…æ”¹è¿›',
    priority: 'low',
    estimatedChanges: '5-10%',
    confidence: 65
  };
}

/**
 * æ­¥éª¤2ï¼šä»£ç†æ‰§è¡Œæ‰€é€‰ç­–ç•¥
 */
export async function executeStrategy(
  context: EditingContext,
  decision: AgentDecision,
  generateText: LLMGenerateFunction
): Promise<string> {
  
  const originalContent = context.chapterContent;
  
  switch (decision.strategy) {
    case 'skip':
      log(context, 'execution', 'Skipping edits - chapter is strong');
      return context.chapterContent;
      
    case 'targeted-edit':
      log(context, 'execution', 'Applying targeted edits');
      const targetedResult = await executeTargetedEdit(context, generateText);
      // Log diff for targeted edits
      if (targetedResult !== originalContent) {
        logDiff(context, originalContent, targetedResult, 'targeted-edit');
      }
      return targetedResult;
      
    case 'regenerate':
      log(context, 'execution', 'æŒ‰ç…§è®¡åˆ’é‡æ–°ç”Ÿæˆç« èŠ‚');
      const regenerateResult = await executeRegeneration(context, generateText);
      // è®°å½•é‡æ–°ç”Ÿæˆçš„å·®å¼‚
      if (regenerateResult !== originalContent) {
        logDiff(context, originalContent, regenerateResult, 'regenerate');
      }
      return regenerateResult;
      
    case 'polish':
      log(context, 'execution', 'Polishing chapter');
      const polishResult = await executePolish(context, generateText);
      // Log diff for polish
      if (polishResult !== originalContent) {
        logDiff(context, originalContent, polishResult, 'polish');
      }
      return polishResult;
      
    default:
      return context.chapterContent;
  }
}

/**
 * è®°å½•æ–‡æœ¬å·®å¼‚ä»¥ä¾¿å¯è§†åŒ–çš„è¾…åŠ©å‡½æ•°
 */
function logDiff(context: EditingContext, before: string, after: string, strategy: string) {
  const entry: AgentLogEntry = {
    timestamp: Date.now(),
    chapterNumber: context.chapterNumber,
    type: 'diff',
    message: `Text changes applied via ${strategy}`,
    beforeText: before,
    afterText: after,
    strategy: strategy
  };
  
  console.log(`ğŸ“ Diff captured for Chapter ${context.chapterNumber} (${strategy})`);
  
  // UI callback
  if (context.onLog) {
    context.onLog(entry);
  }
}

/**
 * Strategy: Targeted Edit - Surgical fixes for specific issues
 */
async function executeTargetedEdit(
  context: EditingContext,
  generateText: LLMGenerateFunction
): Promise<string> {
  
  const { systemPrompt, userPrompt: prompt } = getFormattedPrompt(PromptNames.EDITING_AGENT_TARGETED, {
    critique_notes: context.critiqueNotes,
    chapter_content: context.chapterContent
  });
  
  return await generateText(prompt, systemPrompt, undefined, 0.5, 0.8, 40);
}

/**
 * ç­–ç•¥ï¼šé‡æ–°ç”Ÿæˆ - æŒ‰ç…§è®¡åˆ’å®Œå…¨é‡å†™
 */
async function executeRegeneration(
  context: EditingContext,
  generateText: LLMGenerateFunction
): Promise<string> {
  
  const { systemPrompt, userPrompt: prompt } = getFormattedPrompt(PromptNames.EDITING_AGENT_REGENERATE, {
    chapter_plan_text: context.chapterPlanText,
    moral_dilemma: context.chapterPlan.moralDilemma || 'æœªæŒ‡å®š',
    character_complexity: context.chapterPlan.characterComplexity || 'æœªæŒ‡å®š',
    consequences_of_choices: context.chapterPlan.consequencesOfChoices || 'æœªæŒ‡å®š',
    conflict_type: context.chapterPlan.conflictType || 'æœªæŒ‡å®š',
    tension_level: context.chapterPlan.tensionLevel || 5,
    chapter_content_preview: context.chapterContent.substring(0, 8000) + (context.chapterContent.length > 8000 ? '...ï¼ˆå·²æˆªæ–­ï¼‰' : ''),
    critique_notes: context.critiqueNotes
  });
  
  return await generateText(prompt, systemPrompt, undefined, 0.7, 0.9, 60);
}

/**
 * ç­–ç•¥ï¼šæ¶¦è‰² - åœ¨è®¡åˆ’éªŒè¯åŸºç¡€ä¸Šçš„è½»åº¦æ”¹è¿›
 */
async function executePolish(
  context: EditingContext,
  generateText: LLMGenerateFunction
): Promise<string> {
  
  const { systemPrompt, userPrompt: prompt } = getFormattedPrompt(PromptNames.EDITING_AGENT_POLISH, {
    moral_dilemma: context.chapterPlan.moralDilemma || 'æœªæŒ‡å®š',
    character_complexity: context.chapterPlan.characterComplexity || 'æœªæŒ‡å®š',
    consequences_of_choices: context.chapterPlan.consequencesOfChoices || 'æœªæŒ‡å®š',
    critique_notes: context.critiqueNotes || 'æ— ç‰¹å®šé—®é¢˜',
    chapter_content: context.chapterContent
  });
  
  return await generateText(prompt, systemPrompt, undefined, 0.4, 0.8, 30);
}

/**
 * æ­¥éª¤3ï¼šä»£ç†è¯„ä¼°ç»“æœ
 */
export async function evaluateResult(
  original: string,
  refined: string,
  context: EditingContext,
  generateText: LLMGenerateFunction
): Promise<{ qualityScore: number; changesApplied: string[] }> {
  
  const { systemPrompt: evaluationSystemPrompt, userPrompt: evaluationPrompt } = getFormattedPrompt(PromptNames.EDITING_AGENT_EVALUATION, {
    original_length: original.length,
    refined_length: refined.length,
    moral_dilemma: context.chapterPlan.moralDilemma || 'æœªæŒ‡å®š',
    character_complexity: context.chapterPlan.characterComplexity || 'æœªæŒ‡å®š',
    refined_chapter_preview: refined.substring(0, 3000) + '...'
  });

  try {
    const evaluationSchema = {
      type: 'object' as const,
      additionalProperties: false,
      properties: {
        qualityScore: { type: 'number' as const, description: 'è´¨é‡è¯„åˆ†0-100' },
        changesApplied: { type: 'array' as const, items: { type: 'string' as const }, description: 'å·²åšçš„æ”¹è¿›åˆ—è¡¨' },
        planElementsPresent: { type: 'boolean' as const, description: 'è®¡åˆ’å…ƒç´ æ˜¯å¦å­˜åœ¨ï¼Ÿ' },
        remainingIssues: { type: 'array' as const, items: { type: 'string' as const }, description: 'å‰©ä½™é—®é¢˜' }
      },
      required: ['qualityScore', 'changesApplied', 'planElementsPresent', 'remainingIssues']
    };
    
    const response = await generateText(evaluationPrompt, evaluationSystemPrompt, evaluationSchema, 0.3, 0.7, 20);
    const evaluation = JSON.parse(response);
    
    log(context, 'evaluation', `Quality Score: ${evaluation.qualityScore}/100`, {
      qualityScore: evaluation.qualityScore,
      planElementsPresent: evaluation.planElementsPresent,
      changesApplied: evaluation.changesApplied,
      remainingIssues: evaluation.remainingIssues
    });
    
    return {
      qualityScore: evaluation.qualityScore,
      changesApplied: evaluation.changesApplied || []
    };
  } catch (e) {
    log(context, 'warning', `Evaluation failed: ${e}. Using default score.`);
    return {
      qualityScore: 75, // Default score
      changesApplied: ['Edits applied']
    };
  }
}

/**
 * Main Agent Workflow - Orchestrates the entire editing process with iterative refinement
 */
export async function agentEditChapter(
  context: EditingContext,
  generateText: LLMGenerateFunction
): Promise<EditingResult> {
  
  log(context, 'iteration', `Agent starting work on Chapter ${context.chapterNumber}`);
  
  const MAX_ITERATIONS = 2;
  let iteration = 1;
  let currentContent = context.chapterContent;
  let lastDecision: AgentDecision;
  let lastQualityScore = 0;
  let allChangesApplied: string[] = [];
  
  while (iteration <= MAX_ITERATIONS) {
    log(context, 'iteration', `Iteration ${iteration}/${MAX_ITERATIONS}`);
    
    // Step 1: Analyze and decide strategy
    const iterationContext = { ...context, chapterContent: currentContent };
    const decision = await analyzeAndDecide(iterationContext);
    lastDecision = decision;
    
    // If agent says skip, we're done
    if (decision.strategy === 'skip') {
      log(context, 'success', 'Chapter is strong, no changes needed');
      break;
    }
    
    // Step 2: Execute strategy
    const refinedContent = await executeStrategy(iterationContext, decision, generateText);
    
    // Step 3: Evaluate result
    const { qualityScore, changesApplied } = await evaluateResult(
      currentContent,
      refinedContent,
      context,
      generateText
    );
    
    lastQualityScore = qualityScore;
    allChangesApplied.push(...changesApplied);
    
    // Check if we need another iteration
    const needsRefinement = qualityScore < 70;
    const hasConfidence = decision.confidence >= 60;
    
    if (!needsRefinement) {
      log(context, 'success', `Quality threshold met (${qualityScore}/100)`, { qualityScore });
      currentContent = refinedContent;
      break;
    }
    
    if (iteration >= MAX_ITERATIONS) {
      log(context, 'warning', `Max iterations reached (${qualityScore}/100)`, { qualityScore });
      currentContent = refinedContent;
      break;
    }
    
    // Decide on next iteration strategy
    if (!hasConfidence && decision.strategy !== 'regenerate') {
      log(context, 'iteration', 'Low confidence + low quality â†’ trying regeneration');
      context.critiqueNotes += '\n\nå‰æ¬¡å°è¯•å¤±è´¥ã€‚éœ€è¦æŒ‰ç…§è®¡åˆ’å®Œå…¨é‡æ–°ç”Ÿæˆã€‚';
    } else if (decision.strategy === 'targeted-edit') {
      log(context, 'iteration', 'Targeted edit insufficient â†’ trying regeneration');
      context.critiqueNotes += '\n\né’ˆå¯¹æ€§ç¼–è¾‘ä¸å¤Ÿã€‚éœ€è¦æ›´æ·±å±‚çš„ç»“æ„æ€§ä¿®æ”¹ã€‚';
    } else {
      log(context, 'warning', `Quality still low after ${decision.strategy}`);
    }
    
    currentContent = refinedContent;
    iteration++;
  }
  
  log(context, 'success', `Agent completed Chapter ${context.chapterNumber} after ${iteration} iteration(s)`, {
    finalQuality: lastQualityScore,
    totalChanges: allChangesApplied.length
  });
  
  return {
    refinedContent: currentContent,
    decision: lastDecision,
    changesApplied: allChangesApplied,
    qualityScore: lastQualityScore,
    logs: [] // æ—¥å¿—é€šè¿‡å›è°ƒå‘é€ï¼Œä¸åœ¨æ­¤å­˜å‚¨
  };
}
